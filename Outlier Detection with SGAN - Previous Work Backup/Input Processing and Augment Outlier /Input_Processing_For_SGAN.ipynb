{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert image read from url in csv file to ImageNet Version 2\n",
    "- ** This file intended to **\n",
    "    1. **Process and transform the filtered input csv file into a formal input for Machine Learning. **\n",
    "    2. **Augment outliers data by adding filters, and getting images online**\n",
    "   \n",
    "- Apply different method to process image: **Scipy, Scikit-image, PIL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Packages\n",
    "- [numpy](www.numpy.org) is the main package for scientific computing with Python.\n",
    "- [matplotlib](matplotlib.org) is a library to plot graphs in Python.\n",
    "- [h5py](www.h5py.org) is a common package to interact with a dataset that is stored on an H5 file.\n",
    "- [cv2](opencv.org/) OpenCV is a library of programming functions mainly aimed at real-time computer vision. \n",
    "- [scipy](www.scipy.org) is a Python-based ecosystem of open-source software for mathematics, science, and engineering.\n",
    "- [PIL](pillow.readthedocs.io/en/4.3.x/) is the Python Imaging Library by Fredrik Lundh and Contributors.\n",
    "- [skimage](scikit-image.org/) is a collection of algorithms for image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import h5py\n",
    "#import urllib\n",
    "#import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# METHOD #2: scikit-image\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert Function\n",
    "1. Get image from reading url from csv file\n",
    "2. Resize image\n",
    "3. Convert image to numpy array with shape: (1, IMSIZE, IMSIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "img_width = 64\n",
    "img_height = 64\n",
    "\n",
    "def file_to_imageArray(filename, end_idx):\n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    with open('../images/' + str(filename), 'rU') as f:\n",
    "        readCSV = csv.reader(f, delimiter=',')\n",
    "        interestingrows = [row for idx, row in enumerate(readCSV) if idx in list(range(0,end_idx))]\n",
    "    \n",
    "        images_array = [] # store final result\n",
    "        y = []            # store label result\n",
    "\n",
    "        i = 0\n",
    "        print(\"Start Processing\")\n",
    "        \n",
    "        for row in interestingrows: #for row in readCSV:\n",
    "            label = row[2]\t\t# class label 0 or 1\n",
    "            imageURL = row[1]\t# image url\n",
    "            i = i+1\n",
    "            image = io.imread(imageURL)  # read image from url\n",
    "            # resize and reshape to: (1, image_height, image_width, image_depth)\n",
    "            img_array = scipy.misc.imresize(image, size=(img_width,img_height)).reshape((1, img_width, img_height, 3 ))\n",
    "\n",
    "            if i % 50 == 0:\n",
    "                print(\"Processed the \"+str(i)+\"th image.\")\n",
    "\n",
    "            # Add label to list\n",
    "            y.append(label)\n",
    "\n",
    "            # Add img_array to result by Concatenating image_array to images_array\n",
    "            if len(images_array) == 0:\n",
    "                images_array = img_array\n",
    "            else:\n",
    "                images_array = np.concatenate([images_array, img_array])\n",
    "            \n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(\"Complete processing:\")\n",
    "    print(str(elapsed/(60*60)) + \"hr\")\n",
    "    return [images_array, np.array(y).astype(np.int)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert 50 Outside Front  image to imageNets\n",
    "**imageNet_array: Concatenated result of 50 images **\n",
    "- 50 image_URL with label 0 (normal data)\n",
    "- 50 image_URL with label 1 (outlier data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Processing\n",
      "Processed the 50th image.\n",
      "Complete processing:\n",
      "0.036642682751hr\n"
     ]
    }
   ],
   "source": [
    "outside_front_50 = file_to_imageArray('outside_front_50.csv', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:(50, 64, 64, 3)\n",
      "Y shape:(50,)\n"
     ]
    }
   ],
   "source": [
    "outside_front_X = outside_front_50[0]\n",
    "outside_front_Y = outside_front_50[1]\n",
    "print(\"X shape:\" + str(outside_front_X.shape))\n",
    "print(\"Y shape:\" + str(outside_front_Y.shape))\n",
    "#print(outside_front_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert 100 Outside Front images to imageNets\n",
    "**imageNet_array: Concatenated result of 100 images **\n",
    "- 100 image_URL with label 0 (normal data)\n",
    "- 100 image_URL with label 1 (outlier data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Processing\n",
      "Processed the 50th image.\n",
      "Processed the 100th image.\n",
      "Complete processing:\n",
      "0.0667634130187hr\n"
     ]
    }
   ],
   "source": [
    "outside_front_100 = file_to_imageArray('outside_front_100.csv', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:(100, 64, 64, 3)\n",
      "Y shape:(100,)\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "outside_front_100_X = outside_front_100[0]\n",
    "outside_front_100_Y = outside_front_100[1]\n",
    "print(\"X shape:\" + str(outside_front_100_X.shape))\n",
    "print(\"Y shape:\" + str(outside_front_100_Y.shape))\n",
    "print(outside_front_100_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to h5py file under group \"outside_front_50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File('data.h5','w')\n",
    "#f = h5py.File('data.h5','r+')\n",
    "group=f.create_group('outside_front_50')\n",
    "group.create_dataset('X', data = outside_front_X)    # could add ‘compression=\"gzip\", compression_opts=9’ to compress\n",
    "group.create_dataset('Y', data = outside_front_Y)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File('data.h5','r')\n",
    "group = f['outside_front_50']\n",
    "X = group['X'][:]\n",
    "Y = group['Y'][:]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((50, 64, 64, 3), (50,))\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to h5py file under group \"outside_front_100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#f = h5py.File('data.h5','r+')\n",
    "#del f['outside_front_100']\n",
    "#print(f['outside_front_100'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File('data.h5','r+')\n",
    "group=f.create_group('outside_front_100')\n",
    "group.create_dataset('X', data = outside_front_100_X)    # could add ‘compression=\"gzip\", compression_opts=9’ to compress\n",
    "group.create_dataset('Y', data = outside_front_100_Y)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File('data.h5','r')\n",
    "group = f['outside_front_100']\n",
    "x = group['X'][:]\n",
    "y = group['Y'][:]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((100, 64, 64, 3), (100,))\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert 12330 Outside front unlabelled images (Not use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outside_front_12330 = file_to_imageArray('outside_front.csv', 12330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outside_front_12330_X = outside_front_12330[0]\n",
    "outside_front_12330_Y = outside_front_12330[1]\n",
    "print(\"X shape:\" + str(outside_front_12330_X.shape))\n",
    "print(\"Y shape:\" + str(outside_front_12330_Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#f = h5py.File('data.h5','w')\n",
    "f = h5py.File('data.h5','r+')\n",
    "group=f.create_group('outside_front_12330')\n",
    "group.create_dataset('X', data = outside_front_12330_X, compression=\"gzip\", compression_opts=9)    # could add ‘compression=\"gzip\", compression_opts=9’ to compress\n",
    "group.create_dataset('Y', data = outside_front_12330_Y, compression=\"gzip\", compression_opts=9)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File('data.h5','r')\n",
    "group = f['outside_front_12330']\n",
    "X = group['X'][:]\n",
    "Y = group['Y'][:]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Outliers Data augmentation by adding blur filter, enhance contrast and brightness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Save 50 original cars images and 50 outlier images to local file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download(filename, end_idx):\n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    with open(str(filename), 'rU') as f:\n",
    "        readCSV = csv.reader(f, delimiter=',')\n",
    "        interestingrows = [row for idx, row in enumerate(readCSV) if idx in list(range(0,end_idx))]\n",
    "        i = 0\n",
    "        \n",
    "        for row in interestingrows: #for row in readCSV:\n",
    "            label = row[2]\t\t# class label 0 or 1\n",
    "            imageURL = row[1]\t# image url\n",
    "            # download the image using scikit-image\n",
    "            #print \"downloading %s\" % (url)\n",
    "            i = i+1\n",
    "            image = io.imread(imageURL)  # read image from url\n",
    "            if i <= 50:\n",
    "                io.imsave('images/unsatisfied_images/outliers_orig_%d.jpg' % (i), image)\n",
    "            else:\n",
    "                io.imsave('images/satisfied_images/cars_orig_%d.jpg' % (i-50), image)\n",
    "      \n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(\"Complete processing:\")\n",
    "    print(str(elapsed/(60*60)) + \"hr\")\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x = download('../images/outside_front_100.csv', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Create and Save Blurred version of cars and outliers images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "def blur_image(filepath):\n",
    "    im = Image.open(filepath)\n",
    "    im1 = im.filter(ImageFilter.BLUR)\n",
    "    return im1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (50):\n",
    "    outputPath = 'images/blur/'\n",
    "    inputPath_cars = 'images/satisfied_images/cars_orig_%d.jpg' % (i+1)\n",
    "    blurred_image_cars = blur_image(inputPath_cars)\n",
    "    blurred_image_cars.save(outputPath +'cars_blur_%d.jpg' %(i+1))\n",
    "    \n",
    "    inputPath_outliers = 'images/unsatisfied_images/outliers_orig_%d.jpg' % (i+1)\n",
    "    blurred_image_outliers = blur_image(inputPath_outliers)\n",
    "    blurred_image_outliers.save(outputPath +'outliers_blur_%d.jpg' %(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Create and Save Enhance Brightness version of cars and outliers images \n",
    "- exposure image\n",
    "    - save under '**images/expose**' folder\n",
    "- darker image\n",
    "     - save under '**images/dark**' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_brightness(filepath):\n",
    "    im = Image.open(filepath)\n",
    "    brightness = 7.0  # value > 1: brighter\n",
    "    darkness = 0.4    # value in range 0.0-1.0: darker\n",
    "    enhancer = ImageEnhance.Brightness(im)\n",
    "    bright_image = enhancer.enhance(brightness) # .show() to display image\n",
    "    dark_image = enhancer.enhance(darkness)\n",
    "    return bright_image, dark_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (50):\n",
    "    outputPath_bright = 'images/expose/'\n",
    "    outputPath_dark = 'images/dark/'\n",
    "    \n",
    "    inputPath_cars = 'images/satisfied_images/cars_orig_%d.jpg' % (i+1)\n",
    "    exposed_image_car, darker_image_car = adjust_brightness(inputPath_cars)\n",
    "    exposed_image_car.save(outputPath_bright +'cars_exposure_%d.jpg' %(i+1))\n",
    "    darker_image_car.save(outputPath_dark +'cars_dark_%d.jpg' %(i+1))\n",
    "    \n",
    "    inputPath_outliers = 'images/unsatisfied_images/outliers_orig_%d.jpg' % (i+1)\n",
    "    exposed_image_outlier, darker_image_outlier = adjust_brightness(inputPath_outliers)\n",
    "    exposed_image_outlier.save(outputPath_bright +'outliers_exposure_%d.jpg' %(i+1))\n",
    "    darker_image_outlier.save(outputPath_dark +'outliers_dark_%d.jpg' %(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Outliers data for train and test (Class: 1)\n",
    "\n",
    "### 4.1. Add more outhliers by Reading images from outside_back.csv, outside_right.csv, outside_left.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_otherside_car_images(filename, start_idx, end_idx, outputfilename):\n",
    "    start_time = timeit.default_timer()\n",
    "    with open('../images/'+ str(filename), 'rU') as f:\n",
    "        readCSV = csv.reader(f, delimiter=',')\n",
    "        interestingrows = [row for idx, row in enumerate(readCSV) if idx in list(range(start_idx,end_idx))]\n",
    "        i = 0\n",
    "        for row in interestingrows: #for row in readCSV:\n",
    "            imageURL = row[1]\t# image url\n",
    "            # download the image using scikit-image\n",
    "            i = i+1\n",
    "            image = io.imread(imageURL)  # read image from url\n",
    "            io.imsave('images/otherside_car/%s/%d.jpg' % (outputfilename, i), image) \n",
    "            \n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(\"Complete processing:\" + str(elapsed/(60*60)) + \"hr\")\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete processing:0.0390927216742hr\n",
      "Complete processing:0.037032312221hr\n",
      "Complete processing:0.0372867591514hr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_otherside_car_images('outside_back.csv',0,50, outputfilename = 'backside')\n",
    "download_otherside_car_images('outside_left.csv',0,50, outputfilename ='leftside')\n",
    "download_otherside_car_images('outside_right.csv',0,50,outputfilename ='rightside')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Convert 450 outlier images under 'images' folder to array\n",
    "### 360 for train, 90 for test. Label: 1\n",
    "- 50 black image\n",
    "- 50 exposed image (high brightness)\n",
    "- 50 blurry image\n",
    "- 50 incomplete car image\n",
    "- 50 street/road/house image\n",
    "- 200 otherside image\n",
    "    - 50 backside\n",
    "    - 50 leftside\n",
    "    - 50 rightside\n",
    "    - 50 inside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_to_imageArray(filenames):\n",
    "    start_time = timeit.default_timer()\n",
    "    outlier_images = {}\n",
    "    \n",
    "    for fn in filenames:\n",
    "        outlier_images[str(fn)] = []\n",
    "        print(fn)\n",
    "        for i in range(50):\n",
    "            image = Image.open('images/' + str(fn)+'/%d.jpg'%(i+1))\n",
    "            #print(i)\n",
    "            img_array = scipy.misc.imresize(image, size=(64,64)).reshape((64, 64, 3))\n",
    "            outlier_images[str(fn)].append(img_array)\n",
    "    \n",
    "    return outlier_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blur\n",
      "dark\n",
      "expose\n",
      "incomplete_car\n",
      "street\n",
      "otherside_car/backside\n",
      "otherside_car/leftside\n",
      "otherside_car/rightside\n",
      "otherside_car/inside\n"
     ]
    }
   ],
   "source": [
    "filenames = ['blur','dark', 'expose', 'incomplete_car', 'street', 'otherside_car/backside', \n",
    "             'otherside_car/leftside', 'otherside_car/rightside', 'otherside_car/inside']\n",
    "#filenames = ['street']\n",
    "outliers_images = image_to_imageArray(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((360, 64, 64, 3), (90, 64, 64, 3), (360,), (90,))\n"
     ]
    }
   ],
   "source": [
    "outliers_for_train = []\n",
    "outliers_for_test = []\n",
    "\n",
    "for fn in filenames:\n",
    "    if len(outliers_for_train) == 0:\n",
    "        outliers_for_train = outliers_images[str(fn)][:40] # fetch first 40 data as outliers train\n",
    "        outliers_for_test = outliers_images[str(fn)][40:]  # fetch last 10 data as outliers test\n",
    "    else:\n",
    "        outliers_for_train = np.concatenate([outliers_for_train, outliers_images[str(fn)][:40]])\n",
    "        outliers_for_test = np.concatenate([outliers_for_test, outliers_images[str(fn)][40:]])\n",
    "\n",
    "# Class: Label 1\n",
    "outliers_train_label = np.ones((outliers_for_train.shape[0],),dtype = int)\n",
    "outliers_test_label = np.ones((outliers_for_test.shape[0],),dtype = int)\n",
    "print(outliers_for_train.shape, outliers_for_test.shape, outliers_train_label.shape, outliers_test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Convert 550 outside_front car images from csv file to array (Class: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_to_array(filename, end_idx, num_train = 550):\n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    with open('../images/' + str(filename), 'rU') as f:\n",
    "        readCSV = csv.reader(f, delimiter=',')\n",
    "        interestingrows = [row for idx, row in enumerate(readCSV) if idx in list(range(0,end_idx))]\n",
    "    \n",
    "        images_array = [] # store final result\n",
    "        for row in interestingrows: #for row in readCSV:\n",
    "            label = int(row[2])      # class label 0 or 1\n",
    "            imageURL = row[1]   # image url\n",
    "            if len(images_array) < num_train:\n",
    "                if label == 0:       # only process image with label 0 (satisfied car image)\n",
    "                    image = io.imread(imageURL)  # read image from url\n",
    "                    # resize and reshape to: (1, image_height, image_width, image_depth)\n",
    "                    img_array = scipy.misc.imresize(image, size=(img_width,img_height)).reshape((1, img_width, img_height, 3 ))\n",
    "                    # Add img_array to result by Concatenating image_array to images_array\n",
    "                    if len(images_array) == 0:\n",
    "                        images_array = img_array\n",
    "                    else:\n",
    "                        images_array = np.concatenate([images_array, img_array])\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        labels = np.zeros((num_train,),dtype='int')  # Class: Label 0 \n",
    "    return images_array, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_x, normal_y = file_to_array('outside_front_0.csv', end_idx = 900, num_train = 550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((440, 64, 64, 3), (440,), (110, 64, 64, 3), (110,))\n"
     ]
    }
   ],
   "source": [
    "# Split dataset to train and test dataset\n",
    "normal_train_x = normal_x[:440]\n",
    "normal_train_y = normal_y[:440]\n",
    "normal_test_x = normal_x[440:]\n",
    "normal_test_y = normal_y[440:]\n",
    "print(normal_train_x.shape, normal_train_y.shape, normal_test_x.shape, normal_test_y.shape )\n",
    "#print(str(normal_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Concatenate normal data and outliers to Train dataset\n",
    "- Concatenate `normal_data_for_train` and `outliers_data_for_train` together\n",
    "- Concatenate `normal_data_for_test` and `outliers_data_for_test` together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((800, 64, 64, 3), (800,), (200, 64, 64, 3), (200,))\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.concatenate([normal_train_x, outliers_for_train])\n",
    "y_train = np.concatenate([normal_train_y, outliers_train_label])\n",
    "x_test = np.concatenate([normal_test_x, outliers_for_test])\n",
    "y_test = np.concatenate([normal_test_y, outliers_test_label]) \n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape )\n",
    "print(str(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Save train and test data to h5py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = h5py.File('data.h5','r+')\n",
    "del f['outside_front_1000']\n",
    "#print(f['outside_front_100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to h5py file\n",
    "f = h5py.File('data.h5','r+')\n",
    "group=f.create_group('outside_front_1000')\n",
    "group.create_dataset('X_train', data = x_train)    # could add ‘compression=\"gzip\", compression_opts=9’ to compress\n",
    "group.create_dataset('Y_train', data = y_train)\n",
    "group.create_dataset('X_test', data = x_test) \n",
    "group.create_dataset('Y_test', data = y_test) \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "f = h5py.File('data.h5','r')\n",
    "group = f['outside_front_1000']\n",
    "X_train = group['X_train'][:]\n",
    "Y_train = group['Y_train'][:]\n",
    "X_test = group['X_test'][:]\n",
    "Y_test = group['Y_test'][:]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((800, 64, 64, 3), (800,), (200, 64, 64, 3), (200,))\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(str(Y_train.T))\n",
    "print(str(Y_test.T))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
